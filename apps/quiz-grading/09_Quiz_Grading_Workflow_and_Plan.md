# 智能阅卷（Quiz Grading）现状梳理与下一步计划

本文档整理我们最近围绕“智能阅卷”功能的讨论结论，并将教师实际工作流（批量扫描上传）映射到平台的端到端实现方案。目标是：**先把单份试卷稳定评定跑通，再扩展为批量、复核、沉淀与分析闭环**。

---

## 1. 背景与痛点

### 1.1 现状做法
- 前端按“小题逐题裁切”为图片。
- 对每道题分别请求 OCR / 评分接口。

### 1.2 主要问题
- 逐题请求会触发后端限流（rate limit），在班级批量阅卷时尤其明显。
- “定位每题答案”依赖逐题裁切/逐题调用，整体吞吐受限。

---

## 2. 我们达成的一致：先把单份试卷评定跑通

教师真实工作流（我们要支持的最小闭环）：
1) 老师收到一叠试卷 → 批量扫描为 PDF/图片。  
2) 上传到平台。  
3) 平台拆分出每一位学生的“单份试卷”（多页归档到同一学生）。  
4) 对每一份试卷先得到客观题结果，再得到主观题 AI 评分结果。  
5) 汇总得到整卷结果（可保存/导出/后续人工复核）。

这个闭环跑通后，批量处理就是把“单份评定”流水线并发/排队化。

---

## 3. MinerU 的关键信息：JSON 带 bbox，可做位置归属

你提供的 MinerU JSON 示例已包含：
- `para_blocks[].bbox` / `lines[].bbox` / `spans[].bbox`
- `spans[].content`
- `page_size` / `page_idx`

这意味着我们可以基于 bbox 完成：
- **文字 → 题目区域** 的归属（assignment ROI / 预置坐标）
- 由此得到每题的识别文本/答案（无需逐题 OCR）

> 重要补充：MinerU bbox 只告诉“文字在哪里”，不直接告诉“属于第几题”。要稳定分题，仍需一份“预置位置信息”作为映射基准（来自组卷导入或人工标注）。

---

## 4. 阅卷总体方案（核心链路）

### 4.1 输入与预置位置信息
系统需要一份**预置位置信息（题目定位/ROI）**，用于将 MinerU 的 bbox 归属到“哪一道题”。

我们要支持两种来源（两种选择）：
1) **从智能组卷导入（免标注）**  
   - 组卷端产出试卷结构（题目列表/标准答案/分值）+ 版面定位（每题 page + bbox，必要时带锚点坐标系信息）。  
   - 阅卷端导入后直接生成 assignmentConfig（无需老师手工画框）。
2) **外部试卷/照片导入（需要标注）**  
   - 老师上传模板页（PDF/图片）并手工标注每题 ROI（至少客观题 ROI）。  
   - 生成 assignmentConfig 供后续阅卷复用。

### 4.2 单份试卷评定流水线（推荐实现顺序）
对单份试卷（或逐页）执行：
1) **MinerU 解析**：得到带 bbox 的结构化 JSON。  
2) **bbox 归属**：将 `spans/lines` 分配到对应题目 ROI。  
3) **客观题判分（规则优先）**：  
   - 单选/判断：归一化后等值比较。  
   - 多选：支持不同策略（全对满分/漏选部分分/错选 0）。  
   - 填空：可选容差/单位忽略/同义词表（由前端给老师勾选）。  
4) **主观题评分（LLM/VLM）**：  
   - 把“归属后的主观题识别文本”（必要时附图）发给大模型评分。  
   - 产出 `score + feedback`。  
5) **汇总结果**：客观题 + 主观题 → 总分 + 明细。

---

## 5. 关于“减少请求”的策略结论

我们讨论过两种手段：

### 5.1 合并裁切图（按题型合并）降低 OCR 调用次数
- 选择题一张图、判断题一张图、填空题一张图。
- 适合 OCR 服务返回纯文本、缺少 bbox 的情况。
- 需要额外的标签或顺序映射策略来恢复题号。

### 5.2 整页 MinerU + bbox（更推荐）
- 整页/单份试卷只调用一次 MinerU（或每页一次）。
- 通过 bbox 与“预置位置信息”对齐，直接得到每题文本。
- 更适合答题卡/标准卷面，也更可解释、可复核。

在你给的 JSON 已确认 bbox 可用后，后续主路线应以 **5.2** 为主。

---

## 6. 我对系统落地的设计思考（关键点）

### 6.1 坐标系与对齐
必须明确 bbox 坐标系：
- MinerU bbox 基于输入图像像素坐标（与 `page_size` 对应）。
- 预置 ROI 也必须落在同一坐标系（或提供锚点/变换矩阵将模板 ROI 映射到学生卷）。

因此 ROI 的表达建议支持两种：
- 绝对像素 bbox（适合固定分辨率的渲染流程）
- 归一化 bbox（x/w、y/h），适配不同分辨率输入

### 6.2 “文字归属题目”的判定策略
推荐从简单可靠开始：
- 用 `span bbox` 的中心点 `(cx, cy)` 判断落入哪一题 ROI；
- 或用 `IoU / 覆盖率` 作为更稳的归属标准；
- 同一题内按 y/x 排序拼接为题目文本。

### 6.3 客观题规则要可配置、可追溯
老师需要在前端选择策略（我们已达成）：
- 多选计分策略
- 填空容差/单位忽略/同义词表

并且应随同提交结果一起保存（便于复核与追责）。

---

## 7. 下一步计划（可交付拆分）

### P0：MinerU bbox 能力验证（已完成关键一步）
- ✅ 已确认 MinerU JSON 包含 bbox + content（你提供的示例）。

### P1：后端提供结构化 OCR JSON（给前端/服务端消费）
- 输出：按页的 spans/lines 列表（bbox + content），以及 page_size。  
- 目标：不再只返回 markdown；提供稳定的结构化结果接口。

### P2：单份试卷评定 MVP（客观题先规则、主观题走大模型）
- 输入：一份学生卷（多页可先逐页处理）。  
- 输出：每题识别文本、客观题得分、主观题评分结果、总分与明细。

### P3：批量拆分与队列化
- 批量扫描 PDF → 拆分为单份试卷（按 QR/页序/锚点规则）。  
- 并发控制：对 MinerU/LLM 调用做队列与限速，避免触发限流。

### P4：两种定位来源的产品化
- 从智能组卷导入（免标注）  
- 外部试卷手工标注（需要标注）  
两条路径最终都生成统一的 `assignmentConfig`，供后续评定复用。

### P5：人工复核与重新发布（后续闭环）
- 复核 UI：查看题目区域、识别文本、评分依据，允许调分/改答案归属。  
- 重新发布：更新提交、写回成绩与事件。

---

## 8. 结论

我们已明确：在 MinerU 能提供 bbox 的前提下，**“整页一次 MinerU + bbox 对齐预置 ROI”**是稳定且可扩展的阅卷主路线。

为了兼容实际教学场景，需要同时支持两种定位来源：
- 来自智能组卷：自动生成题目 ROI（免标注）
- 来自外部试卷：老师手工标注 ROI（可复用配置）

接下来优先把“单份试卷评定 MVP”做实：客观题规则判分、主观题大模型评分、结果汇总与保存。

